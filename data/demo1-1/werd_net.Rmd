```{r}
library(dplyr)
SET_WN_JPN <- list(FILE = "../db/wnjpn.db")
wordnet_sqlite <- dplyr::src_sqlite(path = SET_WN_JPN$FILE, create = FALSE)
```
```{r}
list2string = function(string_list){
  return(paste(unlist(string_list), collapse="\",\""))
}
```

```{r}
search_similars = function(words){
  pos = c("n", "a", "v")
  hit_words <- tbl(
    wordnet_sqlite,
    sql(
      paste("SELECT * FROM word WHERE lemma IN (\"",list2string(words),"\") AND pos IN (\"", list2string(pos), "\")", sep="")
    )
  )%>%as.data.frame()

  wordids = c()
  for(id in hit_words$wordid){
    wordids = c(wordids, as.character(id))
  }
  
  hit_words_synset <- tbl(
    wordnet_sqlite,
    sql(
      paste("SELECT * FROM sense WHERE wordid IN (\"", list2string(wordids),"\")", sep="")
    )
  )%>%as.data.frame()

  synsets = c()
  for(s in hit_words_synset$synset){
    synsets = c(synsets, as.character(s))
  }
  syn_word <- dplyr::left_join(
    x = dplyr::tbl(
      src = wordnet_sqlite,
      from = sql(
        paste("SELECT synset, wordid, freq, src FROM sense WHERE synset IN (\"", list2string(synsets), "\")", sep = "")
      )
    ), 
    y = dplyr::tbl(src = wordnet_sqlite, from = "word"),
    by = c("wordid")
  )%>%as.data.frame()
  return(filter(syn_word, lang=="jpn"))
}
```

```{r}
search_similars(c("ご飯"))$lemma
```
```{r}
library(RMeCab)
library(igraph)
# install.packages("doBy")
# library(doBy) # which.maxn
library(dplyr) # filter
```

```{r}
answer_reason_list = read.csv("./data/answer_demo1.csv")$reason
answer_morphenes_list = c()
for(r in answer_reason_list){
  mor = RMeCabC(r, 1)
  answer_morphenes_list = c(answer_morphenes_list, mor[names(unlist(mor)) == "名詞" | names(unlist(mor)) == "動詞" | names(unlist(mor)) == "形容詞"])
}
answer_like_morphenes_list= search_similars(answer_morphenes_list)$lemma
answer_like_morphenes_list=answer_like_morphenes_list[!answer_like_morphenes_list %in% c("する", "こと", "ある")]
```

```{r}
analyze = function(path) {
  remarks_df = read.csv(path)
  raw_mor = list()
  morphenes = list()
  for(r in remarks_df$remark) {
    mor = RMeCabC(r, 1)
    morphenes = append(morphenes, list(mor[names(unlist(mor)) == "名詞" | names(unlist(mor)) == "動詞" | names(unlist(mor)) == "形容詞"])) 
    raw_mor = append(raw_mor, list(mor))
  }

  adjacency_df <- data.frame(matrix(0, length(morphenes), length(morphenes)))
  tmp = list()
  for (i in 1:length(morphenes)) {
    r1 <- unlist(morphenes[i]) 
    im = list()
    for (j in i+1:length(morphenes)) {
      inte <- intersect(r1, unlist(morphenes[j]))
      inte <- intersect(inte, answer_like_morphenes_list)
      if (length(inte) > 0) {
        adjacency_df[i, j] = length(inte)
        im = append(im, inte)
        print(inte)
      }
    }
    tmp = append(tmp, list(im))
  }

  net <- graph_from_adjacency_matrix(as.matrix(adjacency_df) , mode="directed")

  plot(net, vertex.size = 3, vertex.label = NA, edge.arrow.size=.2, edge.width=.4, edge.curved=.1) #1

  bt = betweenness(net)
  deg = degree(net, mode="out")

  remarks_bt_df = remarks_df
  remarks_bt_df$betweenness = bt
  remarks_deg_df = remarks_df
  remarks_deg_df$degree = deg

  attendees = unique(remarks_df$attendee)
  
  important_remarks_index = c()
  for (a in attendees) {
    target_bw_df = filter(remarks_bt_df, attendee == a)
    plot(target_bw_df$index, target_bw_df$betweenness, type="b", col="royalblue3", pch=15, cex=2, lwd=2, lty=1)
    title(paste("Betweeness: ", a))
  }
  
  for (a in attendees) {
    target_deg_df = filter(remarks_deg_df, attendee == a)
    plot(target_deg_df$index, target_deg_df$degree, type="b", col="royalblue3", pch=15, cex=2, lwd=2, lty=1)
    title(paste("OutDegree: ", a))
  }
  for(a in attendees){
    tar_df = filter(remarks_bt_df, attendee==a)
    tar_df = filter(tar_df, betweenness>0)
    print(paste(a, mean(tar_df$betweenness)))
  }
}
```


```{r}
analyze("./data/demo1-1.csv")
analyze("./data/demo1-2.csv")
```

